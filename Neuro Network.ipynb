{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02da23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries to run the code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import NaiveBayesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "# using the variable sw to hold all stopwords that are in English\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf2ab540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_preprocess.tsv.txt\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382c68c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>respon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    respon\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b71fdd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000 entries, 0 to 10999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    11000 non-null  object\n",
      " 1   respon  11000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 172.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf3426fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(data):\n",
    "    aux_list = []\n",
    "    flag = False\n",
    "    for phase_word in data:\n",
    "        word_list = []\n",
    "        for word in phase_word.split():\n",
    "            word = word.lower()\n",
    "            if flag and not word in sw:\n",
    "                flag = False\n",
    "                word_list.append('not_'+word)\n",
    "                continue\n",
    "            if re.search('(n\\'t)$|(not)|(no)|(never)', word):\n",
    "                flag = True\n",
    "                continue\n",
    "            if not word in sw:\n",
    "                word = re.sub('[\\W_0-9]', ' ', word)\n",
    "                word_list.append(word)\n",
    "        aux_list.append(' '.join(word_list))\n",
    "    return aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfa85572",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaning_data(df['text'])\n",
    "y = df['respon']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6e509b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This CountVectorizer is used to represent the words as a list of values, instead of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit(X)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db4669d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "275/275 [==============================] - 7s 23ms/step - loss: 0.4637 - accuracy: 0.8138\n",
      "Epoch 2/10\n",
      "275/275 [==============================] - 6s 22ms/step - loss: 0.1884 - accuracy: 0.9369\n",
      "Epoch 3/10\n",
      "275/275 [==============================] - 8s 28ms/step - loss: 0.0911 - accuracy: 0.9701\n",
      "Epoch 4/10\n",
      "275/275 [==============================] - 7s 25ms/step - loss: 0.0533 - accuracy: 0.9817\n",
      "Epoch 5/10\n",
      "275/275 [==============================] - 6s 22ms/step - loss: 0.0354 - accuracy: 0.9877\n",
      "Epoch 6/10\n",
      "275/275 [==============================] - 6s 22ms/step - loss: 0.0261 - accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "275/275 [==============================] - 6s 22ms/step - loss: 0.0204 - accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "275/275 [==============================] - 6s 22ms/step - loss: 0.0166 - accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "275/275 [==============================] - 6s 22ms/step - loss: 0.0136 - accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "275/275 [==============================] - 6s 22ms/step - loss: 0.0111 - accuracy: 0.9981\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.8536\n",
      "Accuracy: 0.8536363840103149\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n",
    "model.add(Dense(units=3, activation='sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, \n",
    "          epochs=10, verbose=1)\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd87480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has created!\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "model.save('mymodel.h5')\n",
    "print(\"Model has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34cf4194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.8536\n",
      "Test accuracy:  85.3636384010315 %\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('mymodel.h5')\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "\n",
    "LSTM_accuracy = scores[1]*100\n",
    "\n",
    "print('Test accuracy: ', scores[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db74dca0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4800\\1153935445.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcleansing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_text5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mguess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "#A function for predict the sentiment\n",
    "import re \n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "input_text = \"\"\"makanan di sini tidak enak\"\"\"\n",
    "input_text2 = \"\"\"makanan di sini gak enak\"\"\"\n",
    "input_text3 = \"\"\"makanan di sini engga enak\"\"\"\n",
    "input_text4 = \"\"\"makanan di sini kurang enak\"\"\"\n",
    "input_text5 = \"\"\"presiden indonesia keren sekali\"\"\"\n",
    "input_text6 = \"\"\"presiden indonesia pergi ke timur tengah\"\"\"\n",
    "\n",
    "def cleansing(sent):\n",
    "    # Mengubah kata menjadi huruf kecil semua dengan menggunakan fungsi lower()\n",
    "    string = sent.lower()\n",
    "    # Menghapus emoticon dan tanda baca menggunakan \"RegEx\" dengan script di bawah\n",
    "    string = re.sub(r'[^a-zA-Z0-9]', ' ', string)\n",
    "    return string\n",
    "\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "text = [cleansing(input_text5)]\n",
    "predicted = tokenizer.texts_to_sequences(text)\n",
    "guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "model = load_model('mymodel.h5')\n",
    "prediction = model.predict(guess)\n",
    "polarity = np.argmax(prediction[0])\n",
    "hasil = sentiment[polarity]\n",
    "\n",
    "print(\"Text: %s\" % text[0])\n",
    "print(\"Sentiment: %s\" % sentiment[polarity])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
